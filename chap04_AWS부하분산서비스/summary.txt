4.1 Amazon ELB

OSI 7 계층 관련
	: 계층이 높아질수록 이전 계층을 기본적으로 깔고가면서 +α 시킨다는 느낌
		: ex )  ARP 가 MAC 을 사용하긴 해도, IP 까지 사용해야해서 2계층이 아닌 3계층에 속함

	:  아무리 더 높은 계층이 기본적으로 그 아래의 계층을 활용한다고 해도, 일반적으로는 그 아래 계층에서는 작동 불가 >> 그 아래 계층 이상의 계층에 속해있다는건, 그 아래 계층 이상의 무언갈 필요로 했단 말이니까. 
		: 그러니까 자신이 속해있는 계층에서만 작동 가능

	: HTTP 는 7계층이었다!


레거시 legacy >>  낡은 기술. 
	: 남아있긴 하지만 더이상 선호되진 않는.

로드 밸런싱 load blanancing , 부하분산 >> 서버 - 클라이언트 환경에서, 서버가 클라이언트 요청을 받아 처리하는 과정에서 발생하는 부하(연산작업)에 대해 동일한 목적을 수행하는 다수의 서버에 분산 처리하는 기능	
	: 간단하게 말하면, 트래픽을 (서버로) 효율적으로 배분하는 기능.
	: "부하분산" == "로드 밸런싱" . 같은 뜻.
	: 부하분산을 사용 효과 >> 고가용성, 내결함성이 향상 
		고가용성 High availability >>시스템을 항시 사용 가능하게 하는 기능
		내결함성 Fault tolerance >>시스템 일부에 결함이 있더라도 계속 작동할 수 있게 하는 능력

로드 밸런서 load balancer >> 부하분산을 실행시키는 대상




Amazon ELB Elastic Load Balancing : Amazon EC2 인스턴스에서 운영중인 애플리케이션, 서비스로 유입되는 트래픽을 자동 분산 처리하는 기술
	: 여러 가용영역에서 작동
	: 지원
		: HTTP(S) , SSL 등 다양한 프로토콜
		: SSL 암호화 
		: 사용자가 같은 인스턴스에서 세션을 유지 가능
		: 네트워크 및 어플리케이션 수준의 로드밸런싱

	: 활용 방안 >> 다른 AWS 서비스와 짬뽕하여 유용하게 쓰인다
		: AWS 의 Cloudwatch 와 함께 >> 로그와 메트릭을 모니터링 
		: AWS 의 Autoscaling 과 함께 >> 트래픽이 증가할 때 자동으로 인스턴스를 추가하거나 제거하면서 애플리케이션 가용성을 유지

	: 원리 
		(0) 클라이언트가 ELB 의 DNS 주소로 트래픽을 전달(= request 를 보냄)
		(1)  로드 밸런서에서 클라이언트 request 를 수신받고, 클라이언트와 연결을 유지한 상태에서, request 를 수신하기 위해 리스너를 "등록"

		(2) 로드밸런서가 수신한 클라이언트 request 를 처리할 대상 그룹을 선택.

		(3) 로드밸런서가 ( 앞서 선택한 "대상 그룹" 내에서 ) request 를 처리할 대상을 딱 특정하고, 해당 대상으로 request 를 분산(=전달). 
			: 로드 밸런서는 각 대상의 상태를 모니터링하고 있어. 가용하지 않은 대상에겐 request 를 분산시키지 않음.
		
		(4) 분산된 request 대해 대상이 반환한 response 를 로드밸런서가 클라이언트에게 반환
 



	: 주요 구성 요소
		: 로드 밸런서는 가용영역 단위로, 리스너는 리전 단위로 배포함으로써 ELB가 각 가용영역으로 트래픽을 분산시키는걸 가능하게 한다.

		1. 로드 밸런서 Load Balancer >> 클라이언트와 직접적으로 소통( request 받고 response 전달 )하는 역할 + 내부적으론 클라이언트로부터 받은 request(트래픽)를 (상태가 정상인) 대상 그룹에 정의된 서버로 분배하는 역할
			: 일종의 라우터.
			: 가용영역 단위로, 로드 밸런서 "노드" 로써 배포된다.
			: 종류 >> 트래픽의 프로토콜종류, 서비스 목정, 대상 등 따라 4가지의 로드 밸런서를 제공
				(1) CLB Classic Load Balancer >> 가장 초기에 출시된 로드 밸런서
					: 잘 안쓴다. 레거시.
						: 서버의 주소가 변경되면 로드 밸런스를 새로 생성해야됨
						: 기능적 한계 (포트, 헤더 등을 수정 불가)
					: 4계층, 7계층 ( Application layer ) 로드 밸런서		
					: 7계층 로드 밸런싱 >>	 HTTP/HTTPS 요청의 내용을 기반으로 트래픽을 분배	
							: 프로토콜 >> HTTP/HTTPS 지원

						: 4계층 로드 밸런싱 >> IP 주소와 포트 번호를 기준으로 트래픽을 분배
							: 프로토콜 >> SSL/TLS 지원


				(2) ALB Application Load Balancer >> 웹 어플리케이션(HTTP/HTTPS)에 특화된 로드 밸런서
					: 7 계층 로드 밸런서 >> HTTP/HTTPS 지원. 
					    : HTTP/HTTPS 프로토콜 기반 다양한 라우팅 기능 제공
						1. URL path 기반 라우팅 
						2. host 기반 라우팅
						3. 쿼리 스트링 기반 라우팅 

					: 람다를 대상 그룹 지정 가능

				(3) NLB Network Load Balancer >> 대규모 트래픽처리와 빠른 응답에 특화된 로드 밸런서
					: 4 계층 로드 밸런서 >> TCP, UDP, SSL/TLS 프로토콜 지원
						: 신뢰성,안정성 등을 이유로 (아무리 대규모라해도) UDP 보단 TCP사용
						: 7계층인 ALB에 비해선 저수준 >> 비교적 빠르고 & 대규모 트래픽을 처리하는데 용이. (= 성능이 좋다)

					: (일반적인 로드 밸런서완 달리) 클라이언트 IP 주소를 원래 IP 주소로 보존 가능
						: 일반적인 로드 밸런서 >> 중간에 로드 밸런서가 클라이언트의 트래픽을 받으면, 클라이언트의 IP 주소를 로드 밸런서 자신의 IP 주소로 대체한다. 

						: NLB에서 이 기능은 특별한 설정 없이 기본적으로 제공 << 이는 NLB가 레이어 4(전송 계층)에서 작동하기 때문
						: 사용자 분석을 해야하는 경우 유용

					: (4가지 로드 맬런서 중 유일하게) 고정 IP 사용 가능

					: 주로 게임 서버, VolP 서비스, 미디어 스트리밍 등에서 사용

			


				(4) GWLB GateWay Load Balancer >> 네트워크 트래픽을 (중간에 거치는, 경유용) 다른 네트워크의 대상 그룹(서드파티)으로 부하분산 처리하는 로드 밸런서
					: 주로 보안 강화 목적으로 사용
					: 3계층 , 4계층 로드 밸런서 >> IP 주소기반 라우팅 과 TCP, UDP 프로토콜 지원
					: GWLB, GWLB Endpoint, GWLB Endpoint Service 
						: GWLB 를 사용하기 위해선 GWLB Endpoint, GWLB Endpoint Service 를 추가적으로 사용 필수
			
						: GWLB >> GWLB Endpoint Service와 서드파티, 서드 파티와 GWLBE 간의 통신을 중계하는 역할
							: GWLB 자체는 다른 네트워크 내부에, 서드파티와 함께 있음

						: GWLB Endpoint Service >> 클라이언트와 GWLB 간의 통신을 중계하는 역할.
							: 클라이언트에게 직접적으로 request 를 받고, response 를 하게 된다. 
							: GWLB 와 함께 다른 네트워크 내부에 있음
						
						: GWLBE GWLB Endpoint >> GWLB와 (실제 목적지로 하는) 대상 그룹간의 통신을 중계하는 역할
							: 실제로 서비스를 제공하는 대상 그룹과 함꼐 있음 


					: https://kim-dragon.tistory.com/167
					: https://choiblog.tistory.com/169


		2. 대상 그룹 Target Group >> 로드 밸런서로부터 트래픽을 분배당할 하나 이상의 엔드포인트(예: EC2 인스턴스, Lambda 함수, IP 주소 등)를 정의하는 그룹
			: 일종의 (트래픽을전송받는) 네트워크 장치 그룹.


		3. 리스너 Listener >> 로드 밸런서가 받은 request 대해 적용할 rule 과 그에 대한 action(=그 규칙을 만족하는 request 일 경우 해당 request 를 어디로 라우팅 시킬건지) 을 정의 
			: 일종의 라우팅 테이블
			: 리전 단위로 배포된다.
			: 허용 가능한 포트와 프로토콜 등을 정의하여, 특정 대상 그룹으로 트래픽을 라우팅할 수 있게 해준다
				: 다양한 프로토콜을 지원



	: ELB 를 생성할 때 로드 밸런서와 통신하는 방식
		: 인터넷 경계 로드 밸런서 >> 외부에서 직접 로드 밸런서에 접근하는 방식
		: 내부 로드 밸런서 >> 외부의 접근이 차단된 격리된 네트워크(=내부 네트워크)에서 로드 밸런서를 사용하는 방식

	: ELB 교차 로드 밸런싱 Cross-Zone Load Balancing 
		: 트래픽 분배를 인스턴스 단위로 n빵해준다
		: 활성화 시킬 수도 있고, 비활성화 시킬 수도 있다
			: 교차로드밸런싱기능이 비활성화된 경우, 각 (상태가 정상인) 가용영역 내에 인스턴스가 몇개냐 그런거 전혀 고려 없이 가용영역 단위로 n빵 시키게된다. 
			: 반면 교차로드밸런싱기능이 활성화된 경우, (상태가 정상인) 가용영역 들 내의 인스턴스들 단위로, 고르게 n 빵 시켜준다.
			: 어떤 서비스를 사용하느냐 따라서 교차 로드 밸런싱 기능이 디폴트로 활성화 되있기도 하고 비활성화 되있기도 하다
		: 기본적으로는 "로드 밸런서 수준"에서 설정하고, (필요하다면) 세부적으로는 "대상 그룹 수준"에서 설정한다
			: 로드 밸런서 수준에서의 설정 >> 교차 로드 밸런싱 기능 자체를 활성화 할건지의 여부. 그러니까 걍 가용영역 단위로 n빵할건지, 대상 그룹 내부의 인스턴스 단위로 n빵할건지를 결정.

			: 대상 그룹 수준에서의 설정 >> (해당 대상그룹이 트래픽을 받는다면) 각 인스턴스가 어느 정도의 비율로 받게 될 건지를 설정. 


-----------------------------------------------------------------------------------------------------

4.2 ALB 와 NLB 를 이용한 로드 밸런싱 구성

프로비저닝 provisioning : (필요할 때 바로 사용가능하도록) 준비해두는 것.
	: https://jake-seo-dev.tistory.com/210


IaC Infrastructure As Code : (수동으로 자원을 만들지 않고) 코드를 통해 자원/인프라를 제공.생성


DevOps


배포 과정 :
	1. 개발자가 코드를 원격 저장소에 올림
	2. 원격 저장소에 올라간 코드가, 아래의 과정을 모두 통과
		(1) build
		(2) test
		(3) release

	3. (모두 통과하고) 빌드된 형태로 배포 서버에 전달됨
	4. 배포 서버가 애플리케이션 서버에 최종 배포를 함

배포 자동화 : 한번의 클릭 혹은 명령어 입력을 통해 전체 배포 과정을 자동으로 진행하는 것


파이프라인 Pipeline : 소스 코드의 관리부터 실제 서비스로의 배포 과정을 연결한 구조.
	: 파이프라인은 전체 배포 과정을 여러 Stage 로 분리
		1. Source 단계 : 원격저장소에 관리되고 있는 소스 코드에 변경 사항이 일어날 경우 이를 감지하고 다음 단계(Build 단계)로 전달.
		2. Build 단계 :  코드를 컴파일/빌드/테스트 및 빌드된 형태로 다음단계(Deploy단계)로 전달.
		3. Deploy 단계 : 빌드를 실제 서비스에 반영

	: ( CI/CD ) 파이프라인을 구축한다 == 배포 자동화 시스템을 구축한다
		CI/CD 
			: CI Continous Integration >> 지속적 통합.
				: 코드의 변경 사항이 자동으로 빌드 및 테스트 되어 애플리케이션에 반영된다
			: CD Continouse Delivery/Deployment >> 지속적 제공/배포
				: (변경사항이 있어 새로 빌드 .. 등 하고 배포될 준비가 되면) 자동으로 배포된다
	: https://velog.io/@edith_0318/CICD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8


TCP/UDP + 특정번호 == 특정 프로토콜
	TCP 22 : SSH
	TCP 80 : HTTP
	UDP 161 : SNMP


TCP 와 UDP 느낌 >> 일단 둘 다 네트워크 상으로 데이터를 전송하는 경우 쓰이는 프로토콜. 
	: TCP >> 보안. 신뢰성이 좀 필요한 경우
	: UDP >> 걍 요청-응답만 구현하면 됬지, 그다지 신뢰성이 중요하진 않은 경우


HTTP HyperText Transfer Protocol >> 인터넷서 데이터 주고 받을 수 있게하는 표준 프로토콜
	: 웹 서버 - 클라이언트 구조 , request 보내고  response 반환
	: 다양한 메서드 사용 >> GET , POST, PUT , DELTE
	: 80 번 포트 사용
	
Simple Network Management Protocol >>네트워크를 통해 각 네트워크장비들을 모니터링하고 관리할 수 있게하는 프로토콜 
	: SNMP 자체는 "프로토콜"일 뿐, 이를 활용하여 실제 각 네트워크 장비의 정보를 얻기 위해선 이를 이용하고자하는 장비쪽에 별도의 프로그램을 설치 필요
		:  agent 측에는 SNMP Daemon 과 같은, 해당 agnet 와는 전혀 별개의 소프트웨어가 돌아가고 그 소프트웨어가 SNMP 프로토콜을 사용한 통신을 가능하게 하는 거다.

	: SNMP 구성 요소 
		: agent >> 관리 대상. 정보를 제공하는 하드웨어/소프트웨어 
			: 161 번 UDP 포트 사용 , 예외적으로 TRAP 타입 메세지를 전송하는 경우 162번 UDP 포트 사용

		: manager >> 관리시스템/관리자. 정보를 수집하는 하드웨어/소프트웨어 
			: 162번 UDP 포트 사용
			: 현업에서는 manager 을 NMS Network Management System 이라고도 부른다.
	
 	
	: 동작 방식 >> SNMP 관리자와 agent 간에 메세지를 주고 받음
	: ( agent 와 manage 간 ) 통신을 위해선 UDP를 사용, SNMP 자체는 7 계층 프로토콜

	: 버전 >> SNMPv1 , SNMPv2c, SNMPv3 ... 등 계속 업뎃됬음
	     : 주로 Community String 에 대한 보안 강화를 위한 업데이트
		SNMPv1: SNMP의 첫 버전. 보안이 약해서 잘 안 씀 ( 모든 데이터는 평문 )
		SNMPv2/SNMPv2c: v1에서 보안 문제를 좀 개선
		SNMPv3: 최신버전. Username 과 password 를 넣고, 더 강력한 암호화 적용.
		
	: SNMP Message 의 타입
		: Http 메서드 느낌
		(1) SNMP Get : (관리자 쪽에서 보내는) 장비 정보 조회 메시지

		(2) SNMP Set  : (관리자 쪽에서 보내는) 장비 정보 수정 메시지
			: 잘 사용되진 않음. (네트워크 장비 설정은 주로 네트워크 엔지니어가 직접 변경)

		(3) SNMP TRAP : "에이전트 쪽에서 보내는" 메시지
			: 관리자 쪽에서 요청하지 않아도, 이상 상황 발생시 장비가 보내는 메시지 타입. 관리자가 놓칠 수 있는 부분을 보완하는 역할

 

	: 관련 용어
		: Community String 커뮤니티 값 >> agent 와 manger 간의 인증을 위한 값
			: manager 와 agnet 가 서로 동일한 community string 값을 가지고  있어야 통신이 성립하게됨
			: Community String 속성의 종류
				(1) read-only >>에이전트가 매니저로부터 get request 만 받을 수 있다는 것. (그러니까 단순 조회에 대한 응답만 가능)
				(2) read/write >> 에이전트가 매니저로부터 get request 뿐 아니라 set request 도 받을 수 있다는 것 (조회 뿐 아니라 수정에 대한 작업 및 응답이 가능) 

			: 별다른 설정 없을 시 디폴트론 read-only 속성의 "public"이란 문자열이 Community String 으로 지정된다.
			: https://m.blog.naver.com/aepkoreanet/222101737343

		: Object >> 데이터덩어리. agent 와 manager 가 주고 받은 SNMP message 정보
		: OID Object ID >> Object 의 고유 식별자. 
			: SNMP 에서는 각 네트워크 장비의 기능, 설정이 OID 를 기준으로 구별됨
			: 표기 >> 숫자가 '.'을 기준으로 구분되어 나열된 꼴
				: 사실은 OID 는 트리 구조이고, 이를 '.' 을 기준으로 나열해 표기한 것. 
					: OID 앞쪽 일수록 트리 상단부 노드 , 뒤로 갈수록 말단부 노드
					: 각 노드는 특정한 의미를 가진다 (ex: 특정 벤더, 특정 장비 기능)
				: 그러니까 OID 는 의미 없는, 단순 구별하기 위한 식별자가 아니라, 의미가 있는 일관된 식별자이고 (OID를 통해 벤더와 , 해당 장비의 기능 등을 파악 가능), 그렇다고 이걸 외우는 사람은 ㅂㅅ 인거고 걍 검색해라 . 그때그때.
			: 종류
				(1) Public OID >> 벤더 공통적으로 사용되는 OID 
					: System, Interface, IP 등 벤더 상관없이 필수적인 내용을 제공하는 OID

				(2) Private OID >> 벤더별로 지정되어 사용되는 OID 

		: MIB Management Information Base >>  Object 들의 집합. db의 테이블이라고 봄 됨.
			: 그러니까 쉽게 비유하면
				MIB = 테이블
				Object = 테이블의 row
				OID = 테이블 row 의 ID 컬럼값
 
	: https://aws-hyoh.tistory.com/179



셸 변수
	: 프롬프트 창에 단순히 "변수명=값" 을 입력하여, "해당 셀 세션에서" 일시적으로 사용할 변수를 등록 가능하다
		: 세션이 종료되면 메모리에서 해당 변수는 제거된다. ( SSH 접속이 끊길 때마다도 이전에 설정했던 변수를 사용 불가)	
			: 그렇다고 history 상으로 입력한 명령어 내역에서 까지 사라지는건 아니고, 다만 변수로써의 유효력이 없어지는 것.
		: 셸 변수의 영구적인 저장을 원하면(=새로운 셸 세션이 시작될 때마다 변수가 자동 설정되게 하려면) .bashrc 와 같은 초기화 스크립트에  "export 변수명=값" 꼴로 추가해야한다. 
			: 그리고 이를 설정 후 바로 반영시키려면 source ~/.bashrc

	: 등록한 변수를 사용하는 법 >> $변수명
		: 해당 변수뒤에 바로 다른 문자열 써도 잘 인식된다
			ex ) EC21=13.125.22.69 한 상황에서  $EC21/dev/ 은 13.125.22.69/dev/




리눅스 명령어 관련
	curl >> Client URL . URL 을 사용해서 서버에 데이터를 request 하는,클라이언트 역할을 하는 툴.
		: 형식 >> curl [옵션] [URL]
		: 자주 쓰이는 옵션
			-X : 요청시 사용할 HTTP 메서드의 종류(GET POT PUT PATCH DELTE)를 뒤에 명시 
				: ex ) curl -X GET  http://localhost:8080/user/100

			-d : HTTP POST 요청 데이터 입력

			-H : 전송할 헤더를 지정
				: POST 의 기본 Content type 이 JSON 이 아니라서, JSON 파일을 첨부해보내고 싶으면 별도로 헤더 추가 필수
				: ex ) curl -d '{"key1":"value1", "key2":"value2"}' -H "Content-Type: application/json" -X POST  http://localhost:8080/user/100



		: https://velog.io/@odh0112/Linux-Curl-%EB%AA%85%EB%A0%B9%EC%96%B4



html과 자바스크립트와 PHP
	: html >> 요청하면 걍 준다. 정적 웹 페이지
	: 자바스크립트, php >> 별도로 실행하고 전달된다. 동적  웹페이지
		: 자바스크립트 >> 클라이언트 사이드 스크립트. 클라이언트에게 전달된 후에 실행되고 결과 확인
		: php >> 서버 사이드 스크립트. 서버 쪽에서 실행되고 클라이언트에게 전달됨.
			: 민감한 정보를 포함해야하는 경우 유용

CloudFormation >> AWS 가 제공하는 IaC 서비스
	: 즉, 실습 환경을 "코드" 기반으로 AWS 인프라 리소스( VPC, EC2 등 )를 자동으로 생성하는 기술
	: 지속적 배포를 원하는 CI/CD 파이프 라인과 통합하여 인프라 관리 자동화도 가능
	: 주요 구성 요소
	    : 템플릿을 해석하여 스택을 생성하고, 정의된 AWS 인프라를 생성/변경/삭제
		1. 템플릿 >> AWS 인프라를 정의하는 JSON 또는 YAML 형식의 파일 
			: 일종의 설정 파일.
			: 인프라의 속성, 관계, 종속성 등을 정의 가능 <-- 템플릿 덕분에 종속성 관리 ㅈㄴ 편하다고 한다
			: 문법
				1. 파라미터 : 템플릿의 윗부분에 정의된 변수로, 템플릿의 재사용성을 높임
					!Ref 을 사용해 파일 내부에서 해당 값 사용 가능	

			:  프로비저닝을 할 수 있다?


		2. 스택 >> CloudFormation 의 관리 단위로, 리소스들의 묶음
			: 스택 삭제 시 해당 스택에 속한 모든 인프라도 함께 삭제되는 거임

		3. 리소스 >> CloudFormation으로 생성한, 말 그대로 리소스. (EC2 인스턴스 , Amazon S3 버킷 등..) 
			

		4. 이벤트 >>  CloudFormation 의 "스택"에서 발생하는 모든 이벤트(생성/변경/삭제 등)
			

	: 작동 방식
		1. 템플릿 작성
		2. 해당 템플릿을 CloudFormation 서비스에 업로드
		3. CloudFormation서비스는 해당 템플릿에 따라 스택을 생성하거나 업데이트 함
			; 스택 모니터링 가능 (생성 또는 업데이트 다른 이벤트. 로그 확인 가능.) 


근데 실습 그림에는 리스너가 없네? 뭐임? 리스너는 논리적 개념임?



실습 절차
	1. 기본 인프라를 CloudFormation 으로 배포
		: 절차
			1. 서비스 - CloudFormation 서비스택 - "스택생성" 버튼 클릭
			2. 템플릿 업로드 >> (기존 템플릿 선택 그대로 체크된 채로 냅두고) 템플릿 지정코너에서 Amazon S3 URL 선택 된채로, URL 을 입력 : 교재에서 제공해준 https://cloudneta-aws-book.s3.ap-northeast-2.amazonaws.com/chapter4/elblab.yaml 
					: CloudFormation 템플릿, 즉 yaml 파일을 다운받을 수 있는 URL 임
					: 해당 파일에 정의된 내용
						(1) Parameters 
							1. keyname: >> EC2 인스턴스에 SSH 접근하기 위해 사용하는 기존의 EC2 키 페어 이름
							2. LatestAmiId: >> 어떤 AMI로 EC2 인스턴스 접근할건지 정의

						(2) Resources >> CloudFormation을 통해 생성할 리소스들
							1. VPC 및 기타 네트워크 리소스들
								(1) VPC
									1. ELBVPC
									2. MyVPC

								(2) IGW
									1. ELBIGW
									2. MyIGW
			
								(3) IGW 에 대한 attachment
									: 단순히 IGW 를 생성한다고 끝이 아니라 특정 VPC 에 attach 하는 과정이 필요
									1. ELBIGWAttachment
									2. MyIGWAttachment

								(3) 라우팅 테이블
									: 이게 라우팅 테이블 정의부가 먼저 나왔긴 한데, 이후엔 결국 VPC 내의 서브넷과 연결되어 사용된다

									1. ELBPublicRT
									2. MyPublicRT

								(4) 라우팅 테이블에 IGW 경로 등록
									1. ELBDefaultPublicRoute
									2. MyDefaultPublicRoute

								(5) 서브넷 정의
									1. ELBPublicSN1
									2. ELBPublicSN2
									3. MyPublicSN


								(6) 서브넷과 라우팅 테이블을 연결
									: 그냥 라우팅 테이블을 생성한다고 서브넷에 연결되는게 아님
									: 라우팅테이블은 2개인데 서브넷은 3개라는 점에서 눈치챌 수 있듯이, 같은 VPC 에 속하는 ELBPublicSN1 와 ELBPublicSN2는 같은 라우팅 테이블을 공유한다. (그러니까 서브넷 별 고유한 라우팅 테이블을 가지게 설정한진 않았다)
									1. ELBPublicSNRouteTableAssociation
									2. ELBPublicSNRouteTableAssociation2
									3. MyPublicSNRouteTableAssociation


							2. 보안 그룹 >> EC2 인스턴스에 적용 가능한 보안 그룹을 정의
								(1) MySG >> SSH, ICMP 허용하게 설정됨
								(2) ELBSG >> HTTP, SNMP, SSH, ICMP 허용하게 설정됨

							3. EC2 인스턴스	
							     : Tags 필드를 통해 name 을 설정 가능
								   : KeyName 필드는 키페어 파일명 받는 필드임

							     : UserData 필드를 통해 초기 설정 내용을 명령어로 설정가능- 실습에서는 이를 통해 필요한 툴 및 파일을 미리 설치해놓음
								
								(1) MyEC2 
									: MyVPC에 배포될 t2.micro 인스턴스

								(2) ELBEC21, ELBEC22, ELBEC23
									: ELBVPC 내부 서브넷에 배포될 세 개의 t2.micro 인스턴스
										: ELBPublicSNRouteTableAssociation에는 ELBEC21
										: ELBPublicSNRouteTableAssociation2에는ELBEC22, ELBEC23
	
 



			3. 스택 세부 정보 지정 
				: 스택 이름은 "elblab"
				: KeyName에서 앞서 생성했던 키페어 파일 선택


			4. 스택 옵션 구성 페이지 >> 걍 "다음" 버튼
			5. 검토 >> 걍 "전송" 눌러 최종 생성

			6. 생성된 스택 확인
				: 상태가 CREATED_COMPLETED 로 바뀜 잘 생성된 것. (5분 까지 걸릴 수 있다)
				: 생성된 스택의 리소스 탭으로 들어가면 각 리소스 대해 상세 정보 확인 가능 
					: EC2 인스턴스에 할당된 public IP 확인 위해 이동해봐라





	2. 기본 인프라 환경 검증
		: 절차
			(1) SERVER-1 과 SERVER-2 에 SSH 접속해서 확인해보기
				1. SERVER-1 인스턴스의 상세 페이지로 이동하여 public IP 확인 >> 스택의 리소스탭-ELBEC21의 물리적 ID 클릭해 상세 정보 페이지 이동 : 13.124.73.4

				2. 해당 public IP 로 SSH 접속하여  /var/www/html 의 하위 구조 파악
					: dev 디렉터리가 생성되어있고, xff.php 파일이 있음 << 이는 앞선 템플릿에서 SERVER-1 인스턴스의 정의부에 mkdir /var/www/html/dev 해놔서 그런거임
						/var/www/html
						├── dev
						│   └── index.html
						├── index.html
						└── xff.php

				2. SERVER-2 인스턴스의 상세 페이지로 이동하여 public IP 확인 >> 스택의 리소스탭-ELBEC21의 물리적 ID 클릭해 상세 정보 페이지 이동 : 13.125.152.224
					 : 참고로 SERVER-3 는 52.78.143.54 , MyEC2 는 3.36.113.66

				3. 해당 public IP 로 SSH 접속하여  tree /var/www/html 의 하위 구조 파악
					: mgt 디렉터리가 생성되어있고, xff.php 파일이 있음 << 이는 앞선 템플릿에서 SERVER-2 인스턴스의 정의부에 mkdir /var/www/html/mgt 해놔서 그런거임
						/var/www/html
						├── index.html
						├── mgt
						│   └── index.html
						└── xff.php


			(1) MyEC2 에 SSH 접속해서 확인해보기
				1. curl 요청하기 편하게 세 서버의 IP주소를 일시적 변수로 저장하기 >> "변수명=IP주소" 꼴
					: .bashrc 에 저장안하고 이렇게 저장한 변수들은 이번 셸에서만 일시적으로 사용 가능
					: 다음을 입력
						EC21=13.124.73.4
						EC22=13.125.152.224
						EC23=52.78.143.54
 
				2. 변수 잘 저장됬나 확인 >> "echo $변수명" 꼴
					: 앞서 해당 변수에 할당했던 값이 셸에 출력됨
					: 다음을 입력
						echo $EC21
						echo $EC22
						echo $EC23


				3. SERVER-1 웹 서비스 확인 <-- SERVER-2 , SERVER-3 에 대해서도 이처럼 진행함 됨
					(1) 기본 웹페이지 확인 >> curl $EC21
						: <h1>ELB LAB Web Server-1</h1> 이 출력된다 << 이는 앞선 템플릿에서 SERVER-1 인스턴스의 정의부에  echo "<h1>ELB LAB Web Server-1</h1>" > /var/www/html/index.html 을 써놨기 때문이다.

					(2) /dev 경로의 웹 페이지(index.html) 확인 >> curl $EC21/dev/
						: <h1>ELB LAB Dev Web Page</h1>이 출력된다 << 이는 앞선 템플릿에서 SERVER-1 인스턴스의 정의부에  echo "<h1>ELB LAB Dev Web Page</h1>" > /var/www/html/dev/index.html 을 써놨기 때문이다


					(3) /mgt 경로의 웹 페이지(index.html) 확인 >>  curl $EC21/mgt/
					    : 직접 입력한적이 없는 
						<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
						<html><head>
						<title>404 Not Found</title>
						</head><body>
						<h1>Not Found</h1>
						<p>The requested URL was not found on this server.</p>
						</body></html>
					    이 출력된다. 
							<< 이는 앞선 템플릿에서 SERVER-1 의 인스턴스 정의부에서 딱히 mgt 라는 디렉터리를 생성하지 않았기 때문. ( mgt 리는 디렉터리는 SERVER-2 에 만들어놨다 )




					(4) php 파일 확인 >> curl $EC21/xff.php
					    :  SERVER-1 쪽의 php 파일이 그대로 전달되는게 아니라 (php 특성상 서버사이드 스크립트이므로), 실행된 내용을 response 받는다. 
					       : 그러니까 html 과 같은 정적 파일을 요청했을 때와는 양상이 좀 다른걸 확인 가능

						CloudNeta ELB Test Page

						Sun, 28 Jul 24 11:00:28 +0900

						Current CPU Load:0%

						Last Client IP: 3.36.113.66
						Server Public IP = 13.124.73.4
						Server Private IP: 10.40.1.10



					(4) SNMP 서비스 확인 >> snmpget -v2c -c public $EC21 [ OID값 ]
					     : 실습에서 보안이 강화된 v3 가 아닌 v2c 를 사용한건 보안은 v3 가 더 좋을 지라도 아무래도 암호화같은 로직이 추가되있어, 평문인 v2c 가 걍 실습해보긴 쉬워서 그런 듯. 
					     : -c 는 CommunityString 을 명시하는 옵션명이고, SERVER-1 에서 CommunityString 에 대한 별도 설정을 하지 않았기 때문에 디폴트 CommunityString 값인 public 을 입력함 된다.
					     : 다음의 OID 를 조회
						(1) 1.3.6.1.2.1.1.1.0  >> sysDescr: 장비 설명. 장비 제조사에 따라 크기에 차이가 있음
							: SERVER-1 반환결과 >> SNMPv2-MIB::sysDescr.0 = STRING: Linux SERVER1 4.14.348-265.565.amzn2.x86_64 #1 SMP Fri Jun 28 23:44:17 UTC 2024 x86_64
								: .0 은 ( manager 가 관리하는 장비 중 어떤 장비인거냐 이런걸 나타내는게 아니라)  해당 관리 당하는 장비에 대한 MIB 테이블의 row 를 의미. .0 밖에 안나왔단 소리는 해당 항목에 대한 정보가 1개만 있었다는 것.
						

							:  SERVER-2 반환결과 >> SNMPv2-MIB::sysDescr.0 = STRING: Linux SERVER2 4.14.348-265.565.amzn2.x86_64 #1 SMP Fri Jun 28 23:44:17 UTC 2024 x86_64



						(2) 1.3.6.1.2.1.1.2.0 >> sysObjectID:  장비의 고유한 ID 값. 이 값으로 벤더, 장비 종류 등을 파악 및 관리 가능

							: SERVER-1 반환결과 >> SNMPv2-MIB::sysObjectID.0 = OID: NET-SNMP-MIB::netSnmpAgentOIDs.10


						(3) 1.3.6.1.2.1.1.3.0 >> sysUpTime: 장비가 부팅되어 현재까지 동작한 milli-second 값

							: SERVER-1 반환결과 >> DISMAN-EVENT-MIB::sysUpTimeInstance = Timeticks: (6377902) 17:42:59.02



						(4) 1.3.6.1.2.1.1.5.0 >> sysName: 사용자가 장비에 설정한 장비 이름으로, 설정하지 않으면 Null 값(해당 장비 이름은 IP 주소 혹은 Alias )
							: SERVER-1 반환결과 >> SNMPv2-MIB::sysName.0 = STRING: SERVER1
							: SERVER-2 반환결과 >> SNMPv2-MIB::sysName.0 = STRING: SERVER2
	

	3. ALB를 생성하고 동작 과정을 확인


	4. ALB의 경로 기반 라우팅 기능을 이용한 로드 밸런싱 방법을 구성하고 확인
	5. ALB의 User-Agent 를 활용한 로드 밸런싱 방법을 구성하고 확인
	6. NLB를 생성하고 교차 영역 로드 밸런싱 기능 여부를 동작을 거쳐 확인
	7. ALB와 NLB 의 출발지 IP 보존 방식에 대한 동작 과정 확인
	8. 실습에서 생성한 자원 모두 삭제




	
 


