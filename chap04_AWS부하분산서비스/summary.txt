4.1 Amazon ELB

OSI 7 계층 관련
	: 계층이 높아질수록 이전 계층을 기본적으로 깔고가면서 +α 시킨다는 느낌
		: ex )  ARP 가 MAC 을 사용하긴 해도, IP 까지 사용해야해서 2계층이 아닌 3계층에 속함

	:  아무리 더 높은 계층이 기본적으로 그 아래의 계층을 활용한다고 해도, 일반적으로는 그 아래 계층에서는 작동 불가 >> 그 아래 계층 이상의 계층에 속해있다는건, 그 아래 계층 이상의 무언갈 필요로 했단 말이니까. 
		: 그러니까 자신이 속해있는 계층에서만 작동 가능

	: HTTP 는 7계층이었다!


레거시 legacy >>  낡은 기술. 
	: 남아있긴 하지만 더이상 선호되진 않는.

로드 밸런싱 load blanancing , 부하분산 >> 서버 - 클라이언트 환경에서, 서버가 클라이언트 요청을 받아 처리하는 과정에서 발생하는 부하(연산작업)에 대해 동일한 목적을 수행하는 다수의 서버에 분산 처리하는 기능	
	: 간단하게 말하면, 트래픽을 (서버로) 효율적으로 배분하는 기능.
	: "부하분산" == "로드 밸런싱" . 같은 뜻.
	: 부하분산을 사용 효과 >> 고가용성, 내결함성이 향상 
		고가용성 High availability >>시스템을 항시 사용 가능하게 하는 기능
		내결함성 Fault tolerance >>시스템 일부에 결함이 있더라도 계속 작동할 수 있게 하는 능력

로드 밸런서 load balancer >> 부하분산을 실행시키는 대상




Amazon ELB Elastic Load Balancing : Amazon EC2 인스턴스에서 운영중인 애플리케이션, 서비스로 유입되는 트래픽을 자동 분산 처리하는 기술
	: 여러 가용영역에서 작동
	: 지원
		: HTTP(S) , SSL 등 다양한 프로토콜
		: SSL 암호화 
		: 사용자가 같은 인스턴스에서 세션을 유지 가능
		: 네트워크 및 어플리케이션 수준의 로드밸런싱

	: 활용 방안 >> 다른 AWS 서비스와 짬뽕하여 유용하게 쓰인다
		: AWS 의 Cloudwatch 와 함께 >> 로그와 메트릭을 모니터링 
		: AWS 의 Autoscaling 과 함께 >> 트래픽이 증가할 때 자동으로 인스턴스를 추가하거나 제거하면서 애플리케이션 가용성을 유지

	: 원리 
		(0) 클라이언트가 ELB 의 DNS 주소로 트래픽을 전달(= request 를 보냄)
		(1)  로드 밸런서에서 클라이언트 request 를 수신받고, 클라이언트와 연결을 유지한 상태에서, request 를 수신하기 위해 리스너를 "등록"

		(2) 로드밸런서가 수신한 클라이언트 request 를 처리할 대상 그룹을 선택.

		(3) 로드밸런서가 ( 앞서 선택한 "대상 그룹" 내에서 ) request 를 처리할 대상을 딱 특정하고, 해당 대상으로 request 를 분산(=전달). 
			: 로드 밸런서는 각 대상의 상태를 모니터링하고 있어. 가용하지 않은 대상에겐 request 를 분산시키지 않음.
		
		(4) 분산된 request 대해 대상이 반환한 response 를 로드밸런서가 클라이언트에게 반환
 



	: 주요 구성 요소
		: 로드 밸런서는 가용영역 단위로, 리스너는 리전 단위로 배포함으로써 ELB가 각 가용영역으로 트래픽을 분산시키는걸 가능하게 한다.

		1. 로드 밸런서 Load Balancer >> 클라이언트와 직접적으로 소통( request 받고 response 전달 )하는 역할 + 내부적으론 클라이언트로부터 받은 request(트래픽)를 (상태가 정상인) 대상 그룹에 정의된 서버로 분배하는 역할
			: 일종의 라우터.
			: 가용영역 단위로, 로드 밸런서 "노드" 로써 배포된다.
			: 종류 >> 트래픽의 프로토콜종류, 서비스 목정, 대상 등 따라 4가지의 로드 밸런서를 제공
				(1) CLB Classic Load Balancer >> 가장 초기에 출시된 로드 밸런서
					: 잘 안쓴다. 레거시.
						: 서버의 주소가 변경되면 로드 밸런스를 새로 생성해야됨
						: 기능적 한계 (포트, 헤더 등을 수정 불가)
					: 4계층, 7계층 ( Application layer ) 로드 밸런서		
					: 7계층 로드 밸런싱 >>	 HTTP/HTTPS 요청의 내용을 기반으로 트래픽을 분배	
							: 프로토콜 >> HTTP/HTTPS 지원

						: 4계층 로드 밸런싱 >> IP 주소와 포트 번호를 기준으로 트래픽을 분배
							: 프로토콜 >> SSL/TLS 지원


				(2) ALB Application Load Balancer >> 웹 어플리케이션(HTTP/HTTPS)에 특화된 로드 밸런서
					: 7 계층 로드 밸런서 >> HTTP/HTTPS 지원. 
					    : HTTP/HTTPS 프로토콜 기반 다양한 라우팅 기능 제공
						1. URL path 기반 라우팅 
						2. host 기반 라우팅
						3. 쿼리 스트링 기반 라우팅 

					: 람다를 대상 그룹 지정 가능

				(3) NLB Network Load Balancer >> 대규모 트래픽처리와 빠른 응답에 특화된 로드 밸런서
					: 4 계층 로드 밸런서 >> TCP, UDP, SSL/TLS 프로토콜 지원
						: 신뢰성,안정성 등을 이유로 (아무리 대규모라해도) UDP 보단 TCP사용
						: 7계층인 ALB에 비해선 저수준 >> 비교적 빠르고 & 대규모 트래픽을 처리하는데 용이. (= 성능이 좋다)

					: (일반적인 로드 밸런서완 달리) 클라이언트 IP 주소를 원래 IP 주소로 보존 가능
						: 일반적인 로드 밸런서 >> 중간에 로드 밸런서가 클라이언트의 트래픽을 받으면, 클라이언트의 IP 주소를 로드 밸런서 자신의 IP 주소로 대체한다. 

						: NLB에서 이 기능은 특별한 설정 없이 기본적으로 제공 << 이는 NLB가 레이어 4(전송 계층)에서 작동하기 때문
						: 사용자 분석을 해야하는 경우 유용

					: (4가지 로드 맬런서 중 유일하게) 고정 IP 사용 가능

					: 주로 게임 서버, VolP 서비스, 미디어 스트리밍 등에서 사용

			


				(4) GWLB GateWay Load Balancer >> 네트워크 트래픽을 (중간에 거치는, 경유용) 다른 네트워크의 대상 그룹(서드파티)으로 부하분산 처리하는 로드 밸런서
					: 주로 보안 강화 목적으로 사용
					: 3계층 , 4계층 로드 밸런서 >> IP 주소기반 라우팅 과 TCP, UDP 프로토콜 지원
					: GWLB, GWLB Endpoint, GWLB Endpoint Service 
						: GWLB 를 사용하기 위해선 GWLB Endpoint, GWLB Endpoint Service 를 추가적으로 사용 필수
			
						: GWLB >> GWLB Endpoint Service와 서드파티, 서드 파티와 GWLBE 간의 통신을 중계하는 역할
							: GWLB 자체는 다른 네트워크 내부에, 서드파티와 함께 있음

						: GWLB Endpoint Service >> 클라이언트와 GWLB 간의 통신을 중계하는 역할.
							: 클라이언트에게 직접적으로 request 를 받고, response 를 하게 된다. 
							: GWLB 와 함께 다른 네트워크 내부에 있음
						
						: GWLBE GWLB Endpoint >> GWLB와 (실제 목적지로 하는) 대상 그룹간의 통신을 중계하는 역할
							: 실제로 서비스를 제공하는 대상 그룹과 함꼐 있음 


					: https://kim-dragon.tistory.com/167
					: https://choiblog.tistory.com/169


		2. 대상 그룹 Target Group >> 로드 밸런서로부터 트래픽을 분배당할 하나 이상의 엔드포인트(예: EC2 인스턴스, Lambda 함수, IP 주소 등)를 정의하는 그룹
			: 일종의 (트래픽을전송받는) 네트워크 장치 그룹.


		3. 리스너 Listener >> 로드 밸런서가 받은 request 대해 적용할 rule 과 그에 대한 action(=그 규칙을 만족하는 request 일 경우 해당 request 를 어디로 라우팅 시킬건지) 을 정의 
			: 일종의 라우팅 테이블
			: 리전 단위로 배포된다.
			: 허용 가능한 포트와 프로토콜 등을 정의하여, 특정 대상 그룹으로 트래픽을 라우팅할 수 있게 해준다
				: 다양한 프로토콜을 지원



	: ELB 를 생성할 때 로드 밸런서와 통신하는 방식
		: 인터넷 경계 로드 밸런서 >> 외부에서 직접 로드 밸런서에 접근하는 방식
		: 내부 로드 밸런서 >> 외부의 접근이 차단된 격리된 네트워크(=내부 네트워크)에서 로드 밸런서를 사용하는 방식

	: ELB 교차 로드 밸런싱 Cross-Zone Load Balancing 
		: 트래픽 분배를 인스턴스 단위로 n빵해준다
		: 활성화 시킬 수도 있고, 비활성화 시킬 수도 있다
			: 교차로드밸런싱기능이 비활성화된 경우, 각 (상태가 정상인) 가용영역 내에 인스턴스가 몇개냐 그런거 전혀 고려 없이 가용영역 단위로 n빵 시키게된다. 
			: 반면 교차로드밸런싱기능이 활성화된 경우, (상태가 정상인) 가용영역 들 내의 인스턴스들 단위로, 고르게 n 빵 시켜준다.
			: 어떤 서비스를 사용하느냐 따라서 교차 로드 밸런싱 기능이 디폴트로 활성화 되있기도 하고 비활성화 되있기도 하다
		: 기본적으로는 "로드 밸런서 수준"에서 설정하고, (필요하다면) 세부적으로는 "대상 그룹 수준"에서 설정한다
			: 로드 밸런서 수준에서의 설정 >> 교차 로드 밸런싱 기능 자체를 활성화 할건지의 여부. 그러니까 걍 가용영역 단위로 n빵할건지, 대상 그룹 내부의 인스턴스 단위로 n빵할건지를 결정.

			: 대상 그룹 수준에서의 설정 >> (해당 대상그룹이 트래픽을 받는다면) 각 인스턴스가 어느 정도의 비율로 받게 될 건지를 설정. 


-----------------------------------------------------------------------------------------------------

4.2 ALB 와 NLB 를 이용한 로드 밸런싱 구성

프로비저닝 provisioning : (필요할 때 바로 사용가능하도록) 준비해두는 것.
	: https://jake-seo-dev.tistory.com/210


IaC Infrastructure As Code : (수동으로 자원을 만들지 않고) 코드를 통해 자원/인프라를 제공.생성


DevOps


배포 과정 :
	1. 개발자가 코드를 원격 저장소에 올림
	2. 원격 저장소에 올라간 코드가, 아래의 과정을 모두 통과
		(1) build
		(2) test
		(3) release

	3. (모두 통과하고) 빌드된 형태로 배포 서버에 전달됨
	4. 배포 서버가 애플리케이션 서버에 최종 배포를 함

배포 자동화 : 한번의 클릭 혹은 명령어 입력을 통해 전체 배포 과정을 자동으로 진행하는 것


파이프라인 Pipeline : 소스 코드의 관리부터 실제 서비스로의 배포 과정을 연결한 구조.
	: 파이프라인은 전체 배포 과정을 여러 Stage 로 분리
		1. Source 단계 : 원격저장소에 관리되고 있는 소스 코드에 변경 사항이 일어날 경우 이를 감지하고 다음 단계(Build 단계)로 전달.
		2. Build 단계 :  코드를 컴파일/빌드/테스트 및 빌드된 형태로 다음단계(Deploy단계)로 전달.
		3. Deploy 단계 : 빌드를 실제 서비스에 반영

	: ( CI/CD ) 파이프라인을 구축한다 == 배포 자동화 시스템을 구축한다
		CI/CD 
			: CI Continous Integration >> 지속적 통합.
				: 코드의 변경 사항이 자동으로 빌드 및 테스트 되어 애플리케이션에 반영된다
			: CD Continouse Delivery/Deployment >> 지속적 제공/배포
				: (변경사항이 있어 새로 빌드 .. 등 하고 배포될 준비가 되면) 자동으로 배포된다
	: https://velog.io/@edith_0318/CICD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8


근데 실습 그림에는 리스너가 없네? 뭐임? 리스너는 논리적 개념임?

CloudFormation >> AWS 가 제공하는 IaC 서비스
	: 즉, 실습 환경을 "코드" 기반으로 AWS 인프라 리소스( VPC, EC2 등 )를 자동으로 생성하는 기술


	: 특징. 장점
		: 인프라 관리 자동화  
			: 지속적 배포를 원하는 CI/CD 파이프 라인과 통합 가능
	: 주요 구성 요소
	    : 템플릿을 해석하여 스택을 생성하고, 정의된 AWS 인프라를 생성/변경/삭제
		1. 템플릿 >> AWS 인프라를 정의하는 JSON 또는 YAML 형식의 파일 
			: 일종의 설정 파일.
			: 인프라의 속성, 관계, 종속성 등을 정의 가능 <-- 템플릿 덕분에 종속성 관리 ㅈㄴ 편하다고 한다
			:  프로비저닝을 할 수 있다?


		2. 스택 >> CloudFormation 의 관리 단위로, 리소스들의 묶음
			: 스택 삭제 시 해당 스택에 속한 모든 인프라도 함께 삭제되는 거임

		3. 리소스 >> CloudFormation으로 생성한, 말 그대로 리소스. (EC2 인스턴스 , Amazon S3 버킷 등..) 
		4. 파라미터 >> 스택을 생성할 때 전달할 수 있는 매개변수
			: 템플릿의 재사용성을 높임

		5. 이벤트 >>  CloudFormation 의 "스택"에서 발생하는 모든 이벤트(생성/변경/삭제 등)
			

	: 작동 방식
		1. 템플릿 작성
		2. 해당 템플릿을 CloudFormation 서비스에 업로드
		3. CloudFormation서비스는 해당 템플릿에 따라 스택을 생성하거나 업데이트 함
			; 스택 모니터링 가능 (생성 또는 업데이트 다른 이벤트. 로그 확인 가능.) 


실습 절차
	1. 기본 인프라를 CloudFormation 으로 배포
	2. 기본 인프라 환경 검증
	3. ALB를 생성하고 동작 과정을 확인
	4. ALB의 경로 기반 라우팅 기능을 이용한 로드 밸런싱 방법을 구성하고 확인
	5. ALB의 User-Agent 를 활용한 로드 밸런싱 방법을 구성하고 확인
	6. NLB를 생성하고 교차 영역 로드 밸런싱 기능 여부를 동작을 거쳐 확인
	7. ALB와 NLB 의 출발지 IP 보존 방식에 대한 동작 과정 확인
	8. 실습에서 생성한 자원 모두 삭제




	
 


